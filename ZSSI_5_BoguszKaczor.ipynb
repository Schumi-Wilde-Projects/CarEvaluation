{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42a3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6638d",
   "metadata": {},
   "source": [
    "Na początku wczytano dane o samochodach z pliku:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53a8eccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>accept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1723</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1724</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>med</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1726</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>med</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>5more</td>\n",
       "      <td>more</td>\n",
       "      <td>big</td>\n",
       "      <td>high</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1728 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     buying  maint  doors persons lug_boot safety accept\n",
       "0     vhigh  vhigh      2       2    small    low  unacc\n",
       "1     vhigh  vhigh      2       2    small    med  unacc\n",
       "2     vhigh  vhigh      2       2    small   high  unacc\n",
       "3     vhigh  vhigh      2       2      med    low  unacc\n",
       "4     vhigh  vhigh      2       2      med    med  unacc\n",
       "...     ...    ...    ...     ...      ...    ...    ...\n",
       "1723    low    low  5more    more      med    med   good\n",
       "1724    low    low  5more    more      med   high  vgood\n",
       "1725    low    low  5more    more      big    low  unacc\n",
       "1726    low    low  5more    more      big    med   good\n",
       "1727    low    low  5more    more      big   high  vgood\n",
       "\n",
       "[1728 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = pd.read_csv('car.data', encoding='utf-8')\n",
    "cars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2dc26e",
   "metadata": {},
   "source": [
    "Następnie przekonwertowano nazwy klas decyzyjnych na wartości liczbowe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32b7743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['buying'].replace(['low', 'med', 'high', 'vhigh'], [0,1,2,3], inplace=True)\n",
    "cars['maint'].replace(['low', 'med', 'high', 'vhigh'], [0,1,2,3], inplace=True)\n",
    "cars['doors'].replace(['2', '3', '4', '5more'], [0,1,2,3], inplace=True)\n",
    "cars['persons'].replace(['2', '4', 'more'], [0,1,2], inplace=True)\n",
    "cars['lug_boot'].replace(['small', 'med', 'big'], [0,1,2], inplace=True)\n",
    "cars['safety'].replace(['low', 'med', 'high'], [0,1,2], inplace=True)\n",
    "cars['accept'].replace(['unacc', 'acc', 'good', 'vgood'], [0,1,2,3], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db97f04",
   "metadata": {},
   "source": [
    "Oddzielono też parametry wejściowe od klas decyzyjnych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aab1158",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error, mean_absolute_error, classification_report\n",
    "\n",
    "x = cars.drop(\"accept\", axis=1)\n",
    "y = cars[\"accept\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1be484",
   "metadata": {},
   "source": [
    "Następnie wyznaczono błędy pomiaru i współczynniki TP (true positive), TN (true negative), FP (false positive) i FN (false negative):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052c3519",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train: list = []\n",
    "X_test: list = []\n",
    "y_train: list = []\n",
    "y_test: list = []\n",
    "\n",
    "def display_errors(no_of_splits: int, dt_max_depth: int) -> None:\n",
    "    predictions = []\n",
    "    mean_absolute_errors = []\n",
    "    mean_square_errors = []\n",
    "    TPRs = []\n",
    "    TNRs = []\n",
    "    FPRs = []\n",
    "    FNRs = []\n",
    "    k_folds = KFold(n_splits = no_of_splits)\n",
    "    DT_classifier = DecisionTreeClassifier(max_depth=dt_max_depth, criterion='entropy', random_state=42)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(k_folds.split(x)):\n",
    "        X_train, X_test = x.iloc[train_index,:], x.iloc[test_index,:]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        DT_classifier.fit(X_train, y_train)\n",
    "        prediction = DT_classifier.predict(X_test)\n",
    "        cm = confusion_matrix(y_test, prediction)\n",
    "        predictions.append(prediction)\n",
    "        print(\"Confusion matrix for fold #\" + str(i + 1))\n",
    "        print(cm)\n",
    "        print(\"Classification report for fold #\" + str(i + 1))\n",
    "        print(classification_report(y_test, prediction))\n",
    "        # Wyświetlić tutaj metryki MAE, MSE, TP rate, TN rate, FP rate, FN rate, sumować do tablicy i pod koniec wyświetlić\n",
    "        # średnią i odchylenie standardowe dla tych metryk\n",
    "        mae = mean_absolute_error(y_test, prediction)\n",
    "        mean_absolute_errors.append(mae)\n",
    "        mse = mean_squared_error(y_test, prediction)\n",
    "        mean_square_errors.append(mse)\n",
    "        print(\"Mean absolute error for fold #\" + str(i + 1))\n",
    "        print(mae)\n",
    "        print(\"Mean squared error for fold #\" + str(i + 1))\n",
    "        print(mse)\n",
    "        FP = cm.sum(axis=0) - np.diag(cm)  \n",
    "        FN = cm.sum(axis=1) - np.diag(cm)\n",
    "        TP = np.diag(cm)\n",
    "        TN = cm.sum() - (FP + FN + TP)\n",
    "\n",
    "        print(\"TP rate for fold #\" + str(i + 1) + \" (unacc, acc, good, vgood)\")\n",
    "        TPR = TP/(TP+FN)\n",
    "        TPRs.append(TPR)\n",
    "        print(TPR)\n",
    "        print(\"TN rate for fold #\" + str(i + 1) + \" (unacc, acc, good, vgood)\")\n",
    "        TNR = TN/(TN+FP) \n",
    "        TNRs.append(TNR)\n",
    "        print(TNR)\n",
    "        print(\"FP rate for fold #\" + str(i + 1) + \" (unacc, acc, good, vgood)\")\n",
    "        FPR = FP/(FP+TN)\n",
    "        FPRs.append(FPR)\n",
    "        print(FPR)\n",
    "        print(\"FN rate for fold #\" + str(i + 1) + \" (unacc, acc, good, vgood)\")\n",
    "        FNR = FN/(TP+FN)\n",
    "        FNRs.append(FNR)\n",
    "        print(FNR)\n",
    "\n",
    "        print(\"=======================================\")\n",
    "        \n",
    "    print(\"Mean for MAE:\")\n",
    "    print(np.mean(np.asarray(mean_absolute_errors)))\n",
    "    print(\"Stdev for MAE:\")\n",
    "    print(np.std(np.asarray(mean_absolute_errors)))\n",
    "    print(\"Mean for MSE:\")\n",
    "    print(np.mean(np.asarray(mean_square_errors)))\n",
    "    print(\"Stdev for MSE:\")\n",
    "    print(np.std(np.asarray(mean_square_errors)))\n",
    "\n",
    "def train(test_size: float, no_of_splits: int, dt_max_depth: int) -> None:\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=test_size)\n",
    "    k_folds = KFold(n_splits = no_of_splits)\n",
    "    DT_classifier = DecisionTreeClassifier(max_depth=dt_max_depth, criterion='entropy', random_state=42)\n",
    "    DT_classifier.fit(X_train, y_train)\n",
    "    y_pred = DT_classifier.predict(X_test)\n",
    "    cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(cf_matrix)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bdbb8d",
   "metadata": {},
   "source": [
    "Następnie wytrenowano dane na optymalnych parametrach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3034ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[279  25   0   0]\n",
      " [  7  76   0   3]\n",
      " [  0  10   0  10]\n",
      " [  0   5   0  17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95       304\n",
      "           1       0.66      0.88      0.75        86\n",
      "           2       0.00      0.00      0.00        20\n",
      "           3       0.57      0.77      0.65        22\n",
      "\n",
      "    accuracy                           0.86       432\n",
      "   macro avg       0.55      0.64      0.59       432\n",
      "weighted avg       0.85      0.86      0.85       432\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train(0.25, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eb4d288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for fold #1\n",
      "[[242  64]\n",
      " [  0  40]]\n",
      "Classification report for fold #1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88       306\n",
      "           1       0.38      1.00      0.56        40\n",
      "\n",
      "    accuracy                           0.82       346\n",
      "   macro avg       0.69      0.90      0.72       346\n",
      "weighted avg       0.93      0.82      0.85       346\n",
      "\n",
      "Mean absolute error for fold #1\n",
      "0.18497109826589594\n",
      "Mean squared error for fold #1\n",
      "0.18497109826589594\n",
      "TP rate for fold #1 (unacc, acc, good, vgood)\n",
      "[0.79084967 1.        ]\n",
      "TN rate for fold #1 (unacc, acc, good, vgood)\n",
      "[1.         0.79084967]\n",
      "FP rate for fold #1 (unacc, acc, good, vgood)\n",
      "[0.         0.20915033]\n",
      "FN rate for fold #1 (unacc, acc, good, vgood)\n",
      "[0.20915033 0.        ]\n",
      "=======================================\n",
      "Confusion matrix for fold #2\n",
      "[[263   5]\n",
      " [ 44  34]]\n",
      "Classification report for fold #2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.98      0.91       268\n",
      "           1       0.87      0.44      0.58        78\n",
      "\n",
      "    accuracy                           0.86       346\n",
      "   macro avg       0.86      0.71      0.75       346\n",
      "weighted avg       0.86      0.86      0.84       346\n",
      "\n",
      "Mean absolute error for fold #2\n",
      "0.1416184971098266\n",
      "Mean squared error for fold #2\n",
      "0.1416184971098266\n",
      "TP rate for fold #2 (unacc, acc, good, vgood)\n",
      "[0.98134328 0.43589744]\n",
      "TN rate for fold #2 (unacc, acc, good, vgood)\n",
      "[0.43589744 0.98134328]\n",
      "FP rate for fold #2 (unacc, acc, good, vgood)\n",
      "[0.56410256 0.01865672]\n",
      "FN rate for fold #2 (unacc, acc, good, vgood)\n",
      "[0.01865672 0.56410256]\n",
      "=======================================\n",
      "Confusion matrix for fold #3\n",
      "[[193  38   0]\n",
      " [  0  91  24]\n",
      " [  0   0   0]]\n",
      "Classification report for fold #3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91       231\n",
      "           1       0.71      0.79      0.75       115\n",
      "           3       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.82       346\n",
      "   macro avg       0.57      0.54      0.55       346\n",
      "weighted avg       0.90      0.82      0.86       346\n",
      "\n",
      "Mean absolute error for fold #3\n",
      "0.24855491329479767\n",
      "Mean squared error for fold #3\n",
      "0.3872832369942196\n",
      "TP rate for fold #3 (unacc, acc, good, vgood)\n",
      "[0.83549784 0.79130435        nan]\n",
      "TN rate for fold #3 (unacc, acc, good, vgood)\n",
      "[1.         0.83549784 0.93063584]\n",
      "FP rate for fold #3 (unacc, acc, good, vgood)\n",
      "[0.         0.16450216 0.06936416]\n",
      "FN rate for fold #3 (unacc, acc, good, vgood)\n",
      "[0.16450216 0.20869565        nan]\n",
      "=======================================\n",
      "Confusion matrix for fold #4\n",
      "[[191  16   1   0]\n",
      " [  0  71   5  12]\n",
      " [  0  23   0   0]\n",
      " [  0  26   0   0]]\n",
      "Classification report for fold #4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       208\n",
      "           1       0.52      0.81      0.63        88\n",
      "           2       0.00      0.00      0.00        23\n",
      "           3       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.76       345\n",
      "   macro avg       0.38      0.43      0.40       345\n",
      "weighted avg       0.74      0.76      0.74       345\n",
      "\n",
      "Mean absolute error for fold #4\n",
      "0.3536231884057971\n",
      "Mean squared error for fold #4\n",
      "0.5797101449275363\n",
      "TP rate for fold #4 (unacc, acc, good, vgood)\n",
      "[0.91826923 0.80681818 0.         0.        ]\n",
      "TN rate for fold #4 (unacc, acc, good, vgood)\n",
      "[1.         0.74708171 0.98136646 0.96238245]\n",
      "FP rate for fold #4 (unacc, acc, good, vgood)\n",
      "[0.         0.25291829 0.01863354 0.03761755]\n",
      "FN rate for fold #4 (unacc, acc, good, vgood)\n",
      "[0.08173077 0.19318182 1.         1.        ]\n",
      "=======================================\n",
      "Confusion matrix for fold #5\n",
      "[[189   6   0   2]\n",
      " [  0  63   0   0]\n",
      " [  0  26   0  20]\n",
      " [  0  13   0  26]]\n",
      "Classification report for fold #5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       197\n",
      "           1       0.58      1.00      0.74        63\n",
      "           2       0.00      0.00      0.00        46\n",
      "           3       0.54      0.67      0.60        39\n",
      "\n",
      "    accuracy                           0.81       345\n",
      "   macro avg       0.53      0.66      0.58       345\n",
      "weighted avg       0.74      0.81      0.76       345\n",
      "\n",
      "Mean absolute error for fold #5\n",
      "0.24347826086956523\n",
      "Mean squared error for fold #5\n",
      "0.3536231884057971\n",
      "TP rate for fold #5 (unacc, acc, good, vgood)\n",
      "[0.95939086 1.         0.         0.66666667]\n",
      "TN rate for fold #5 (unacc, acc, good, vgood)\n",
      "[1.         0.84042553 1.         0.92810458]\n",
      "FP rate for fold #5 (unacc, acc, good, vgood)\n",
      "[0.         0.15957447 0.         0.07189542]\n",
      "FN rate for fold #5 (unacc, acc, good, vgood)\n",
      "[0.04060914 0.         1.         0.33333333]\n",
      "=======================================\n",
      "Mean for MAE:\n",
      "0.23444919158917651\n",
      "Stdev for MAE:\n",
      "0.0714822447193428\n",
      "Mean for MSE:\n",
      "0.32944123314065504\n",
      "Stdev for MSE:\n",
      "0.15666141363977806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Mistrz Yoda\\AppData\\Local\\Temp\\ipykernel_34532\\548127726.py:44: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "C:\\Users\\Mistrz Yoda\\AppData\\Local\\Temp\\ipykernel_34532\\548127726.py:56: RuntimeWarning: invalid value encountered in true_divide\n",
      "  FNR = FN/(TP+FN)\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "display_errors(5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a6ee18",
   "metadata": {},
   "source": [
    "# Regresja logistyczna (Logistic Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0854f36",
   "metadata": {},
   "source": [
    "Kolejnym krokiem było dokonanie regresji logistycznej danych:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1690d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(n_jobs=-1, random_state=42, solver='saga')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "# Initialize a Logistic Regression classifier.\n",
    "logreg = LogisticRegression(solver='saga', multi_class='auto', random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the classifier.\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07631465",
   "metadata": {},
   "source": [
    "Następnie dokonano klasyfikacji danych testowych i walidacji krzyżowej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3d92ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "log_pred=logreg.predict(X_test)\n",
    "\n",
    "# CV score\n",
    "logreg_cv = cross_val_score(logreg,X_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2572ce",
   "metadata": {},
   "source": [
    "Następnie obliczono średni błąd kwadratowy, średni błąd bezwzględny, dokładność trenowania oraz dokładność walidacji krzyżowej:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b05ce71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (MSE): 0.264\n",
      "Mean absolute error (MAE): 0.204\n",
      "Accuracy: 0.826\n",
      "CV Accuracy: 0.825\n"
     ]
    }
   ],
   "source": [
    "# The mean squared error (relative error).\n",
    "print(\"Mean squared error (MSE): %.3f\" % mean_squared_error(y_test, log_pred))\n",
    "# Explained average absolute error (average error).\n",
    "print(\"Mean absolute error (MAE): %.3f\" % mean_absolute_error(y_test, log_pred))\n",
    "# Explained variance score: 1 is perfect prediction.\n",
    "print('Accuracy: %.3f' % logreg.score(X_test, y_test))\n",
    "# CV Accuracy\n",
    "print('CV Accuracy: %.3f' % logreg_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28e2e95",
   "metadata": {},
   "source": [
    "Następnie dokonano klasyfikacji danych testowych za pomocą perceptronu wielowarstwowego (ang. Multi-Layer Perceptron - MLP):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "036b8541",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=5, max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a Multi-layer Perceptron classifier.\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(5),max_iter=1000, random_state=42, shuffle=True, verbose=False)\n",
    "\n",
    "# Train the classifier.\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7bc21a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Make predictions.\n",
    "mlp_pred = mlp.predict(X_test)\n",
    "\n",
    "# CV score\n",
    "mlp_cv = cross_val_score(mlp,X_train,y_train,cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fbeb40",
   "metadata": {},
   "source": [
    "Następnie obliczono wspomniane wyżej metryki dla nowego klasyfikatora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15a06843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error (MSE): 0.090\n",
      "Mean absolute error (MAE): 0.081\n",
      "Accuracy: 0.924\n",
      "CV Accuracy: 0.920\n"
     ]
    }
   ],
   "source": [
    "# The mean squared error (relative error).\n",
    "print(\"Mean squared error (MSE): %.3f\" % mean_squared_error(y_test, mlp_pred))\n",
    "\n",
    "# Explained average absolute error (average error).\n",
    "print(\"Mean absolute error (MAE): %.3f\" % mean_absolute_error(y_test, mlp_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction.\n",
    "print('Accuracy: %.3f' % mlp.score(X_test, y_test))\n",
    "\n",
    "# CV Accuracy\n",
    "print('CV Accuracy: %.3f' % mlp_cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3330267",
   "metadata": {},
   "source": [
    "# Wnioski"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906f3c3",
   "metadata": {},
   "source": [
    "Klasyfikacja perceptronem wielowarstwowym dawała większą dokładność niż regresja logistyczna, a błąd, zarówno względny jak i bezwzględny, był dużo mniejszy. Zatem w przypadku analizowanych danych bardziej efektywna jest klasyfikacja za pomocą perceptronu wielowarstwowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a6d523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
